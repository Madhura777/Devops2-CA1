{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":86518,"databundleVersionId":9809560,"sourceType":"competition"}],"dockerImageVersionId":31089,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-10T17:12:14.586723Z","iopub.execute_input":"2025-08-10T17:12:14.587035Z","iopub.status.idle":"2025-08-10T17:12:14.906676Z","shell.execute_reply.started":"2025-08-10T17:12:14.587010Z","shell.execute_reply":"2025-08-10T17:12:14.905859Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/llm-classification-finetuning/sample_submission.csv\n/kaggle/input/llm-classification-finetuning/train.csv\n/kaggle/input/llm-classification-finetuning/test.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# === 1. Imports ===\nimport pandas as pd\nimport numpy as np\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import log_loss\nimport lightgbm as lgb\n\n# === 2. Load data directly from Kaggle input ===\ntrain = pd.read_csv(\"/kaggle/input/llm-classification-finetuning/train.csv\")\ntest = pd.read_csv(\"/kaggle/input/llm-classification-finetuning/test.csv\")\nsample_sub = pd.read_csv(\"/kaggle/input/llm-classification-finetuning/sample_submission.csv\")\n\n# === 3. Label encoding ===\ndef label_from_row(r):\n    if r[\"winner_model_a\"] == 1:\n        return 0\n    elif r[\"winner_model_b\"] == 1:\n        return 1\n    else:\n        return 2\n\ntrain[\"label\"] = train.apply(label_from_row, axis=1)\n\n# === 4. Clean text ===\ndef tidy(s):\n    if pd.isna(s):\n        return \"\"\n    s = str(s)\n    if s.startswith('[\"') and s.endswith('\"]'):\n        s = s[2:-2]\n    return s.strip()\n\ntrain[\"text\"] = (\n    \"PROMPT: \" + train[\"prompt\"].apply(tidy) +\n    \" RESP_A: \" + train[\"response_a\"].apply(tidy) +\n    \" RESP_B: \" + train[\"response_b\"].apply(tidy)\n)\n\ntest[\"text\"] = (\n    \"PROMPT: \" + test[\"prompt\"].apply(tidy) +\n    \" RESP_A: \" + test[\"response_a\"].apply(tidy) +\n    \" RESP_B: \" + test[\"response_b\"].apply(tidy)\n)\n\n# === 5. TF-IDF features ===\ntfidf = TfidfVectorizer(ngram_range=(1, 2), max_features=20000)\nX_all = tfidf.fit_transform(train[\"text\"])\nX_test = tfidf.transform(test[\"text\"])\ny_all = train[\"label\"].values\n\n# === 6. Train/validation split ===\nX_train, X_val, y_train, y_val = train_test_split(\n    X_all, y_all, test_size=0.15, random_state=42, stratify=y_all\n)\n\n# === 7. LightGBM model ===\ndtrain = lgb.Dataset(X_train, label=y_train)\ndval = lgb.Dataset(X_val, label=y_val, reference=dtrain)\n\nparams = {\n    \"objective\": \"multiclass\",\n    \"num_class\": 3,\n    \"metric\": \"multi_logloss\",\n    \"learning_rate\": 0.2,\n    \"verbosity\": -1,\n    \"num_threads\": 4,\n    \"seed\": 42\n}\n\nbst = lgb.train(\n    params,\n    dtrain,\n    valid_sets=[dtrain, dval],\n    num_boost_round=150,\n    callbacks=[\n        lgb.early_stopping(stopping_rounds=20),\n        lgb.log_evaluation(20)\n    ]\n)\n\n# === 8. Validation log loss ===\nval_pred = bst.predict(X_val, num_iteration=bst.best_iteration)\nval_logloss = log_loss(y_val, val_pred, labels=[0, 1, 2])\nprint(f\"Validation multi_logloss: {val_logloss:.6f}\")\n\n# === 9. Retrain on full data ===\ndfull = lgb.Dataset(X_all, label=y_all)\nbst_full = lgb.train(params, dfull, num_boost_round=bst.best_iteration)\n\n# === 10. Predict test set ===\ntest_probs = bst_full.predict(X_test, num_iteration=bst_full.best_iteration)\n\n# === 11. Prepare submission ===\nsub = pd.DataFrame(test_probs, columns=[\"winner_model_a\", \"winner_model_b\", \"winner_tie\"])\nsub.insert(0, \"id\", test[\"id\"].values)\nsub.to_csv(\"submission.csv\", index=False)\nprint(\"Submission saved to submission.csv\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T17:12:14.908188Z","iopub.execute_input":"2025-08-10T17:12:14.908545Z","iopub.status.idle":"2025-08-10T17:16:21.776188Z","shell.execute_reply.started":"2025-08-10T17:12:14.908521Z","shell.execute_reply":"2025-08-10T17:16:21.775335Z"}},"outputs":[{"name":"stdout","text":"Training until validation scores don't improve for 20 rounds\n[20]\ttraining's multi_logloss: 1.00279\tvalid_1's multi_logloss: 1.07201\nEarly stopping, best iteration is:\n[15]\ttraining's multi_logloss: 1.01858\tvalid_1's multi_logloss: 1.07072\nValidation multi_logloss: 1.070717\nSubmission saved to submission.csv\n","output_type":"stream"}],"execution_count":2}]}